{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Song Like Prediction Model \n",
    " \n",
    "\n",
    "---\n",
    "\n",
    "## Overview - Problem Statement\n",
    "\n",
    "We will collect data relating to Spotify songs played and if a user likes the song. We will use this to build a classifer prediction model to predict when a user will like a song using the song's features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tools & Data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we Import Libraries. WE will import them all to be safe\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "import requests \n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "---\n",
    "\n",
    "### Objectives\n",
    "- Determine where and how to access the full list of sub-reddits titles\n",
    "- Import data to my server for anlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "---\n",
    "\n",
    "Since we have pulled this data from an internet source and not directly through Spotify's API, we need to  thoroughly examine the data to ensure we ahve a complete and useable set. \n",
    "\n",
    "### Objectives\n",
    "- Evaluate missing data and devise a plan to handle accordingly\n",
    "- Ensure useable data-types, transform data as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2017, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>target</th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.833</td>\n",
       "      <td>204600</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-8.795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>150.062</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>1</td>\n",
       "      <td>Mask Off</td>\n",
       "      <td>Future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.743</td>\n",
       "      <td>326933</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-10.401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>160.083</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>1</td>\n",
       "      <td>Redbone</td>\n",
       "      <td>Childish Gambino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.838</td>\n",
       "      <td>185707</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-7.148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>75.044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>Xanny Family</td>\n",
       "      <td>Future</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  acousticness  danceability  duration_ms  energy  \\\n",
       "0           0        0.0102         0.833       204600   0.434   \n",
       "1           1        0.1990         0.743       326933   0.359   \n",
       "2           2        0.0344         0.838       185707   0.412   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0          0.021900    2     0.165    -8.795     1       0.4310  150.062   \n",
       "1          0.006110    1     0.137   -10.401     1       0.0794  160.083   \n",
       "2          0.000234    2     0.159    -7.148     1       0.2890   75.044   \n",
       "\n",
       "   time_signature  valence  target    song_title            artist  \n",
       "0             4.0    0.286       1      Mask Off            Future  \n",
       "1             4.0    0.588       1       Redbone  Childish Gambino  \n",
       "2             4.0    0.173       1  Xanny Family            Future  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "acousticness        0\n",
       "danceability        0\n",
       "duration_ms         0\n",
       "energy              0\n",
       "instrumentalness    0\n",
       "key                 0\n",
       "liveness            0\n",
       "loudness            0\n",
       "mode                0\n",
       "speechiness         0\n",
       "tempo               0\n",
       "time_signature      0\n",
       "valence             0\n",
       "target              0\n",
       "song_title          0\n",
       "artist              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>582.402066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>504.00000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1512.000</td>\n",
       "      <td>2016.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>acousticness</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.187590</td>\n",
       "      <td>0.259989</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.00963</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>danceability</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.618422</td>\n",
       "      <td>0.161029</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.51400</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>duration_ms</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>246306.197323</td>\n",
       "      <td>81981.814219</td>\n",
       "      <td>16042.000000</td>\n",
       "      <td>200015.00000</td>\n",
       "      <td>229261.000000</td>\n",
       "      <td>270333.000</td>\n",
       "      <td>1004627.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>energy</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.681577</td>\n",
       "      <td>0.210273</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.56300</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.133286</td>\n",
       "      <td>0.273162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>key</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.342588</td>\n",
       "      <td>3.648240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>11.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>liveness</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.190844</td>\n",
       "      <td>0.155453</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.09230</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>loudness</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>-7.085624</td>\n",
       "      <td>3.761684</td>\n",
       "      <td>-33.097000</td>\n",
       "      <td>-8.39400</td>\n",
       "      <td>-6.248000</td>\n",
       "      <td>-4.746</td>\n",
       "      <td>-0.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mode</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.612295</td>\n",
       "      <td>0.487347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>speechiness</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.092664</td>\n",
       "      <td>0.089931</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tempo</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>121.603272</td>\n",
       "      <td>26.685604</td>\n",
       "      <td>47.859000</td>\n",
       "      <td>100.18900</td>\n",
       "      <td>121.427000</td>\n",
       "      <td>137.849</td>\n",
       "      <td>219.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time_signature</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.968270</td>\n",
       "      <td>0.255853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>valence</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.496815</td>\n",
       "      <td>0.247195</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.29500</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>target</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.505702</td>\n",
       "      <td>0.500091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count           mean           std           min  \\\n",
       "Unnamed: 0        2017.0    1008.000000    582.402066      0.000000   \n",
       "acousticness      2017.0       0.187590      0.259989      0.000003   \n",
       "danceability      2017.0       0.618422      0.161029      0.122000   \n",
       "duration_ms       2017.0  246306.197323  81981.814219  16042.000000   \n",
       "energy            2017.0       0.681577      0.210273      0.014800   \n",
       "instrumentalness  2017.0       0.133286      0.273162      0.000000   \n",
       "key               2017.0       5.342588      3.648240      0.000000   \n",
       "liveness          2017.0       0.190844      0.155453      0.018800   \n",
       "loudness          2017.0      -7.085624      3.761684    -33.097000   \n",
       "mode              2017.0       0.612295      0.487347      0.000000   \n",
       "speechiness       2017.0       0.092664      0.089931      0.023100   \n",
       "tempo             2017.0     121.603272     26.685604     47.859000   \n",
       "time_signature    2017.0       3.968270      0.255853      1.000000   \n",
       "valence           2017.0       0.496815      0.247195      0.034800   \n",
       "target            2017.0       0.505702      0.500091      0.000000   \n",
       "\n",
       "                           25%            50%         75%          max  \n",
       "Unnamed: 0           504.00000    1008.000000    1512.000     2016.000  \n",
       "acousticness           0.00963       0.063300       0.265        0.995  \n",
       "danceability           0.51400       0.631000       0.738        0.984  \n",
       "duration_ms       200015.00000  229261.000000  270333.000  1004627.000  \n",
       "energy                 0.56300       0.715000       0.846        0.998  \n",
       "instrumentalness       0.00000       0.000076       0.054        0.976  \n",
       "key                    2.00000       6.000000       9.000       11.000  \n",
       "liveness               0.09230       0.127000       0.247        0.969  \n",
       "loudness              -8.39400      -6.248000      -4.746       -0.307  \n",
       "mode                   0.00000       1.000000       1.000        1.000  \n",
       "speechiness            0.03750       0.054900       0.108        0.816  \n",
       "tempo                100.18900     121.427000     137.849      219.331  \n",
       "time_signature         4.00000       4.000000       4.000        5.000  \n",
       "valence                0.29500       0.492000       0.691        0.992  \n",
       "target                 0.00000       1.000000       1.000        1.000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Examining our data we can see that the data is full as we do not have any nulls in any columns. Also furthermore looking at the data types of each column, we see that each datatype is appropriate and useable.\n",
    "\n",
    "We can drop columns 'Unnamed:0' and 'time_signature' as on first glance these will be less helpful to the model and will simply cause noise.\n",
    "\n",
    "Before any transformation, we have 17 features and 2,017 datapoints to use. We will need to dummify the artist column in order to use this as a feature input into any of our models.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Unnamed: 0' , 'song_title', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns =['artist'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>artist_alt-J</th>\n",
       "      <th>artist_deadmau5</th>\n",
       "      <th>artist_for KING &amp; COUNTRY</th>\n",
       "      <th>artist_one sonic society</th>\n",
       "      <th>artist_tUnE-yArDs</th>\n",
       "      <th>artist_tobyMac</th>\n",
       "      <th>artist_권나무 Kwon Tree</th>\n",
       "      <th>artist_도시총각 Dosichonggak</th>\n",
       "      <th>artist_카우칩스 The CowChips</th>\n",
       "      <th>artist_플랫핏 Flat Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.833</td>\n",
       "      <td>204600</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-8.795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.743</td>\n",
       "      <td>326933</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-10.401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.838</td>\n",
       "      <td>185707</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-7.148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1355 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0        0.0102         0.833       204600   0.434          0.021900    2   \n",
       "1        0.1990         0.743       326933   0.359          0.006110    1   \n",
       "2        0.0344         0.838       185707   0.412          0.000234    2   \n",
       "\n",
       "   liveness  loudness  mode  speechiness  ...  artist_alt-J  artist_deadmau5  \\\n",
       "0     0.165    -8.795     1       0.4310  ...             0                0   \n",
       "1     0.137   -10.401     1       0.0794  ...             0                0   \n",
       "2     0.159    -7.148     1       0.2890  ...             0                0   \n",
       "\n",
       "   artist_for KING & COUNTRY  artist_one sonic society  artist_tUnE-yArDs  \\\n",
       "0                          0                         0                  0   \n",
       "1                          0                         0                  0   \n",
       "2                          0                         0                  0   \n",
       "\n",
       "   artist_tobyMac  artist_권나무 Kwon Tree  artist_도시총각 Dosichonggak  \\\n",
       "0               0                     0                         0   \n",
       "1               0                     0                         0   \n",
       "2               0                     0                         0   \n",
       "\n",
       "   artist_카우칩스 The CowChips  artist_플랫핏 Flat Feet  \n",
       "0                         0                     0  \n",
       "1                         0                     0  \n",
       "2                         0                     0  \n",
       "\n",
       "[3 rows x 1355 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2017, 1355)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We have created our X variable using only the fature data from each song along with the dummified data for song artist. We can see that our original X data frame shape was 2,017 rows with 17 columns and not we have 2,017 rows with 1,355 columns.\n",
    "\n",
    "Since our X shape looks correct, we continue to set our 'y' target variable. Here we have labeled the column 'target' for simplicity with values of 1 if the song is liked and 0 if its unliked.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We have successfully imported our Spotify data. We have explored the data thoroughly to ensure a useable set without missing data or improper values. We have also setup our X and y Datasets to feed our models with appropriate features and target. \n",
    "\n",
    "Our Exploratory Data Analysis is complete. We should move on to building our models\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Construct Logistic Regression Model\n",
    "\n",
    "Lets build our first model which will be a Logistic Regression Model. We will test it with 'C' value of 100 along with 5 cross validations. We will setup a train-test split validation to allow us to test our model's fitness as we build.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "lr = LogisticRegressionCV(\n",
    "    Cs=[100],\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[100], class_weight=None, cv=5, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                     random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5383597883597884"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5485148514851486"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Looking at our first model we can see our baseline score is simply 54% against training data. This is not a very impressive score, and judging by our standards for success, this would not be considered a successful model.\n",
    "\n",
    "Reviewing our train-test split scores, we see that the model is performing with 55% score against testing data. This is a good result that our model is not over-fitting to the training data.\n",
    "\n",
    "We continue further to try other models, pipelines, and features.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "## Construct K Nearest Neighbors Classifier Model\n",
    "\n",
    "Next lets continue our optimmal model constructions by testing a K Nearest Neighbors model  We will initially build this to test with '3' nearest neighbors. \n",
    "\n",
    "We will fit our model to training data established above.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier();\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Knn Training Score is 0.7248677248677249\n",
      " Knn Training Score is 0.5584158415841585\n"
     ]
    }
   ],
   "source": [
    "print(f' Knn Training Score is {knn.score(X_train, y_train)}');\n",
    "print(f' Knn Training Score is {knn.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Here we evaluate using a K Nearest Neighbors classification using the 3 nearest neighbors. We can achieve a better score here when lookign at the training data we achieve 73% score.  \n",
    "\n",
    "When we evaluate our knn model against testing data, our score drops to 56%. This means we are over fitting to our training data with our calculations. \n",
    "\n",
    "To strengthen this KNN model, lets evaluate our score when passing different parameters.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is 0.6812169312169312\n",
      "Testing score is 0.5564356435643565\n"
     ]
    }
   ],
   "source": [
    "print(f'Training score is {knn.score(X_train, y_train)}');\n",
    "print(f'Testing score is {knn.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Examining our different neighbor sizes of KNN, we observe that this reduces our model's over-fitness, however it does not improve our performance scores. This is good information to note, though not helpful in improving our model. \n",
    "\n",
    "Continuing our efforts to improve the model, I will try grid-search capabilities next to find the optimal parameters. To grid search effectively we will scale our data first.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train) #fit transfrom takes mean/standard dev.., then tranformed to z score \n",
    "X_test_scaled = ss.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[100], class_weight=None, cv=5, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                     random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-Scaled score is 0.49404761904761907\n",
      "Testing-Scaled score is 0.49504950495049505\n"
     ]
    }
   ],
   "source": [
    "print(f'Training-Scaled score is {knn.score(X_train_scaled, y_train)}');\n",
    "print(f'Testing-Scaled score is {knn.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We have tried scaling the data to investigate if this can help improve our model performance. Unformatately scaling the data has had the inverse impact and has reduced our improvements. \n",
    "\n",
    "We will re-fit our lr model back to original state and continue with other model evaluateions and pipelines methods. We will re-scale data as needed to operate effectively with the pipeline, however in the event we use this stand alone model, it is better to leave the data un transformed.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[100], class_weight=None, cv=5, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                     random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search lr parameter\n",
    "lr_params = {\n",
    "    'C':[100,10,1,0.1,0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a Grid search\n",
    "gs = GridSearchCV(LogisticRegression(), \n",
    "                  lr_params, \n",
    "                  cv=5, \n",
    "                  n_jobs=-1,\n",
    "                 verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    5.4s finished\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1, param_grid={'C': [100, 10, 1, 0.1, 0.01]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5357142857142857"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5485148514851486"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Completing our Grid Search we see that our lr model performs best when passed '100' for 'C' parameter which is actually our inital best-guess seeting.\n",
    "\n",
    "Using these parameters our lr best score against training data is 53.6% which is our original result. When compared to testign data our best score is 54.9\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "## Evaluation - Confusion Matrix\n",
    "\n",
    "Continuing with our best KNN model, next evaluate the output of our model by taking a look into the values of our confusion matrix.  \n",
    "\n",
    "To produce the confusion metric we wil ned to generate and store our predictions.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130, 120],\n",
       "       [104, 151]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds) #Receive raw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up confusion matrix, using the ravel() function\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 120, 104, 151)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual +</th>\n",
       "      <th>Actual -</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Predicted +</td>\n",
       "      <td>151</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Predicted -</td>\n",
       "      <td>104</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Actual +  Actual -\n",
       "Predicted +       151       120\n",
       "Predicted -       104       130"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = pd.DataFrame(data=[[tp, fp],[fn, tn]], \n",
    "                           columns=['Actual +', 'Actual -'], \n",
    "                           index=['Predicted +', 'Predicted -'])\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = conf_matrix.iloc[0,0] / conf_matrix.iloc[:, 0].sum()\n",
    "specificity = conf_matrix.iloc[1,1] / conf_matrix.iloc[:, 1].sum()\n",
    "accuracy = (conf_matrix.iloc[0, 0] + conf_matrix.iloc[1, 1]) / conf_matrix.iloc[:, :].sum().sum()\n",
    "precision = conf_matrix.iloc[0, 0] / conf_matrix.iloc[0, :].sum()\n",
    "neg_pred_val = conf_matrix.iloc[1, 1] / conf_matrix.iloc[1, :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity       :  59.22%\n",
      "Specificity       :  52.00%\n",
      "Accuracy          :  55.64%\n",
      "Precision (PPV)   :  55.72%\n",
      "Neg PV            :  55.56%\n"
     ]
    }
   ],
   "source": [
    "#Nifty printing format code borrowed from General Assembly ATL Local-lesson\n",
    "label_just = 18\n",
    "spacer = ' '\n",
    "sep = ':'\n",
    "sep_just = 2\n",
    "\n",
    "print('Sensitivity '.ljust(label_just, spacer)     + sep.ljust(sep_just), '{:.2f}%'.format(sensitivity*100))\n",
    "print('Specificity '.ljust(label_just, spacer)     + sep.ljust(sep_just), '{:.2f}%'.format(specificity*100))\n",
    "print('Accuracy '.ljust(label_just, spacer)        + sep.ljust(sep_just), '{:.2f}%'.format(accuracy*100))\n",
    "print('Precision (PPV) '.ljust(label_just, spacer) + sep.ljust(sep_just), '{:.2f}%'.format(precision*100))\n",
    "print('Neg PV '.ljust(label_just, spacer)          + sep.ljust(sep_just), '{:.2f}%'.format(neg_pred_val*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "Examing our confusion matrix our model is optimized for Sensetivity which is good as we are predicting true positives at the highest rate. Our model is trending toward our proper data set but is not yet the best it can be. We can try using a BoosStrap method to continue to iterate toward perfection\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Create a Bootstrap Pipeline\n",
    "At this point our best score is still our KNN model testing with a 'C' value of 100.  In an effort to improve our model, we will next setup a bootstrap pipeline method using several models simultaneously. Lets evaluate this   combination to understand how this impacts our performance\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_scaled = ss.transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcv = LassoCV()\n",
    "knr = KNeighborsRegressor()\n",
    "dtr = DecisionTreeRegressor()\n",
    "br = BaggingRegressor(base_estimator=DecisionTreeRegressor())\n",
    "rfr = RandomForestRegressor()\n",
    "adr = AdaBoostRegressor()\n",
    "svr = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcv.fit(X_train_scaled, y_train)\n",
    "knr.fit(X_train_scaled, y_train)\n",
    "dtr.fit(X_train_scaled, y_train)\n",
    "br.fit(X_train_scaled, y_train)\n",
    "rfr.fit(X_train_scaled, y_train)\n",
    "adr.fit(X_train_scaled, y_train)\n",
    "svr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcv_preds = lcv.predict(X_test_scaled)\n",
    "knr_preds = knr.predict(X_test_scaled)\n",
    "dtr_preds = dtr.predict(X_test_scaled)\n",
    "br_preds = br.predict(X_test_scaled)\n",
    "rfr_preds = rfr.predict(X_test_scaled)\n",
    "adr_preds = adr.predict(X_test_scaled)\n",
    "svr_preds = svr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LassoCV'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method to split-out the 'model-name' from the model information string\n",
    "#Method borrowed from General Assembly lessons\n",
    "str(lcv).split('(')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV\n",
      "Train RMSE: 0.18586838704431535\n",
      "Test RMSE: 0.4019529683040417\n",
      "\n",
      "KNeighborsRegressor\n",
      "Train RMSE: 0.4372835821488514\n",
      "Test RMSE: 0.542600996667126\n",
      "\n",
      "DecisionTreeRegressor\n",
      "Train RMSE: 0.018184824186332698\n",
      "Test RMSE: 0.5431845956491173\n",
      "\n",
      "BaggingRegressor\n",
      "Train RMSE: 0.17100208897170424\n",
      "Test RMSE: 0.44038686862735354\n",
      "\n",
      "RandomForestRegressor\n",
      "Train RMSE: 0.17226328662165794\n",
      "Test RMSE: 0.43410568387718385\n",
      "\n",
      "AdaBoostRegressor\n",
      "Train RMSE: 0.4258825883287354\n",
      "Test RMSE: 0.4421913405492583\n",
      "\n",
      "SVR\n",
      "Train RMSE: 0.13735581603834654\n",
      "Test RMSE: 0.4271688712206993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Method to get the RMSE for each model type\n",
    "#Method sourced from General Assembly lessons\n",
    "for model in [lcv, knr, dtr, br, rfr, adr, svr]:\n",
    "    print(str(model).split('(')[0])\n",
    "    \n",
    "    train_preds = model.predict(X_train_scaled)\n",
    "    train_mse = mean_squared_error(y_train, train_preds)\n",
    "    print(f'Train RMSE: {train_mse**0.5}')\n",
    "    \n",
    "    test_preds = model.predict(X_test_scaled)\n",
    "    test_mse = mean_squared_error(y_test, test_preds)\n",
    "    print(f'Test RMSE: {test_mse**0.5}')\n",
    "    print()\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Above we use a bootstrap method to evaluate several models in a concise process. Here we are using Lasso, K Neighbors Regressor, Decision Tree Regressor, Bagging Regressor, Random Forest Regressor, AdaBoost Regressor, SVR.\n",
    "\n",
    "\n",
    "Initial analysis when using our bootstrap method shows poorer scores and greater overfitting to our training data. In general the models show a trend of overfitting and performing poorly this way.\n",
    "\n",
    "Though we are using many models here, we can see that our best performance continues to lie with our K Neighbors Classifer model.  For now, lets take a moment to backup our transferred data-sets for safety and reproduceability.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  after removing the cwd from sys.path.\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Take the Scores and Titles Dataframes to csg\n",
    "df.to_csv('DF_original.csv')\n",
    "X_train.to_csv('X_Train.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "X_test.to_csv('X_test.csv')\n",
    "y_test.to_csv('y_test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions and Reccomendations\n",
    "\n",
    "When Building a model to predict if a user will like a song based on the user's like history alone, It will be difficult to achieve really high performance score. This is a form of classifying human behaviour whch can be come difficult, yet a successful model is possible. \n",
    "\n",
    "For the features that we have available to construct our model, K nearest neighbors has the best performance. \n",
    "\n",
    "Its recommended to: \n",
    "- continue enhancements of this model by engineering features \n",
    "- collecting more data from this single user as well as other users\n",
    "- Collect lyrics and perform sentiment analysis and use results as predictive features\n",
    "\n",
    "Additionally -In the case of expanding the model to be a general prediction model for any users, we will need to average and classify each of the \"liked/disliked\" from all of the users for a particular song. For our purposes here with a single user, this method is fully functional. For a new user, we would simply need to load their like history to produce new results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
